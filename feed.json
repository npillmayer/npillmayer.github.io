{
    "version": "https://jsonfeed.org/version/1",
    "title": "github.io",
    "description": "",
    "home_page_url": "https://npillmayer.github.io",
    "feed_url": "https://npillmayer.github.io/feed.json",
    "user_comment": "",
    "icon": "https://npillmayer.github.io/media/website/avatar.png",
    "author": {
        "name": "Norbert Pillmayer"
    },
    "items": [
        {
            "id": "https://npillmayer.github.io/posts/bidi-what-you-see-isnt-what-you-get/",
            "url": "https://npillmayer.github.io/posts/bidi-what-you-see-isnt-what-you-get/",
            "title": "Bidi ‚Äì What You See isn&#x27;t What You Get",
            "summary": "I stumbled across the problem of bidirectional text in terminals while trying to test a variant of the Unicode Bidirectional Algorithm. The Unicode consortium publishes a set of bidi&hellip;",
            "content_html": "\n  <p>\n    I stumbled across the problem of bidirectional text in terminals while trying to test a variant of the <a href=\"https://www.unicode.org/reports/tr9/\" target=\"_blank\" rel=\"nofollow noopener\">Unicode Bidirectional Algorithm</a>. The Unicode consortium publishes a set of bidi test-cases, which suffer from being somewhat ‚Äúnon-visual‚Äù. At the end of the day you want to deal with real sentences in real languages and scripts. Preparing that, you face a peculiar problem: how do you display your test output? After all, UAX#9 is about visual ordering of characters. So we just print it to the terminal, do we? But things get confused quickly.\n  </p>\n\n    <h2 id=\"how-hard-can-it-be\">\n      How Hard can It Be?\n    </h2>\n\n  <p>\n    Sure, terminal applications have to manage some of the messy parts of type, just as browsers do: They need fonts with glyphs for almost any foreseeable script, but restricted to monospace. Text shaping is hard, but probably less so for monospaced fonts. And at least there are no difficulties with sophisticated line breaking, complicated layout with different font sizes, graphics, etc. And bidirectional text should be a solved problem. Or is it?\n  </p>\n\n  <p>\n    Turns out for terminal emulators this is an <a href=\"https://terminal-wg.pages.freedesktop.org/bidi/bidi-intro/why-terminals-are-special.html\" target=\"_blank\" rel=\"nofollow noopener\">especially tricky</a> topic!\n  </p>\n\n    <h2 id=\"a-conspiracy-to-not-let-you-bidi\">\n      A Conspiracy to Not Let You Bidi\n    </h2>\n\n  <p>\n    I started my tests from the <a href=\"https://github.com/kovidgoyal/kitty\" title=\"kitty terminal project\" target=\"_blank\" rel=\"nofollow noopener\">kitty</a> terminal I use on MacOS. Let‚Äôs go small first, with just a single phrase in Hebrew:\n  </p>\n\n    <figure class=\"illustration400 post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://npillmayer.github.io/media/posts/6/vte-wikipedia.png\" height=\"630\" width=\"1238\" alt=\"Welcome to Wikipedia (Hebrew)\"  sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://npillmayer.github.io/media/posts/6/responsive/vte-wikipedia-xs.png 320w ,https://npillmayer.github.io/media/posts/6/responsive/vte-wikipedia-sm.png 480w ,https://npillmayer.github.io/media/posts/6/responsive/vte-wikipedia-md.png 768w ,https://npillmayer.github.io/media/posts/6/responsive/vte-wikipedia-xl.png 1024w\">\n      \n    </figure>\n\n  <p>\n    This is the output of the original string, prior to any reordering logic from my test. I‚Äôve not been surprised by the output of MacOS Terminal: obviously it recognizes Hebrew script as right-to-left (RTL) and the errorneous positioning of the ‚Äò!‚Äô is a result of me not specifying overall RTL context. But what about kitty? Perhaps I did get the logical (memory) representation of the phrase wrong, so let‚Äôs check by opening it in vim. Surprise: It looks different, depending on the terminal vim runs in. Strange‚Ä¶!\n  </p>\n\n  <p>\n    When working on bidirectional text there is a requirement for text-editors to help developers enter the logical (memory) order of characters, instead of the visual order. Unfortunately only Emacs has an option to turn off interpreting bidi (these days I program in Go on VSCode, and I‚Äôm <a href=\"https://github.com/microsoft/vscode/issues/83365\" target=\"_blank\" rel=\"nofollow noopener\">not alone in my struggles</a>). But shouldn‚Äôt an editor like vim, running in a terminal‚Äôs raw mode, operate independent of what the terminal emulator considers clever behaviour for bidi? Obviously no.\n  </p>\n\n    <h2 id=\"the-brave-gnome\">\n      The Brave Gnome\n    </h2>\n\n  <p>\n    Diving deeper, I read up on <a href=\"https://ecma-international.org/publications-and-standards/technical-reports/ecma-tr-53/\" target=\"_blank\" rel=\"nofollow noopener\">attempts to standardize bidi handling</a>, including in terminal emulators. After all, the majority of the world‚Äôs population use non-Latin scripts, many of them with non-LTR writing direction. But obviously, as of today the behavious of Mac OS Terminal is the best the industry could come up with. And for good reasons: A terminal is not primarily concerned with paragraphs of text, but rather with (from a typesetting perspective) funny combinations of characters, where application of Unicode recommendations simply falls flat.\n  </p>\n\n  <p>\n    A smart guy named Egmont Koblinger, contributor to a lot of stuff around Linux terminals (joe‚Äâ editor, mc‚Äâ file manager, etc.), came up with a proposal for an <a href=\"https://terminal-wg.pages.freedesktop.org/bidi/\" target=\"_blank\" rel=\"nofollow noopener\">updated standard</a> for bidi handling in terminals. It recommends letting applications decide whether they want implicit or explicit bidi handling, the former more or less meaning the Unicode Bidi Algorithm applied by the terminal. When writing tests for bidi yourself, you most certainly prefer explicit mode, i.e., short-curcuiting the terminal‚Äôs cleverness.\n  </p>\n\n  <p>\n    What‚Äôs best: these ideas have already been implemented in <a href=\"https://wiki.gnome.org/Apps(2f)Terminal(2f)VTE.html\" target=\"_blank\" rel=\"nofollow noopener\">VTE</a>, which underlies the Gnome Terminal window. I installed VTE3 on my Mac, included some lines of code in my test to force VTE in explicit mode, and it gave me this:\n  </p>\n\n    <figure class=\"illustration400 post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://npillmayer.github.io/media/posts/6/vte-wikipedia-2.png\" height=\"630\" width=\"1238\" alt=\"Hebrew on VTE\"  sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://npillmayer.github.io/media/posts/6/responsive/vte-wikipedia-2-xs.png 320w ,https://npillmayer.github.io/media/posts/6/responsive/vte-wikipedia-2-sm.png 480w ,https://npillmayer.github.io/media/posts/6/responsive/vte-wikipedia-2-md.png 768w ,https://npillmayer.github.io/media/posts/6/responsive/vte-wikipedia-2-xl.png 1024w\">\n      \n    </figure>\n\n  <p>\n    Now this made me happy üòÑ! VTE shows me the real thing, the characters in logical (memory) order. While this is of no use to an end-user of terminals, I consider it very valuable for application developers, at least those who have to work on the fine points of international text handling. (VTE even has you covered if your intuition about logical order is from right to left.)\n  </p>\n\n    <h2 id=\"wrap-up\">\n      Wrap Up\n    </h2>\n\n  <p>\n    Terminals, text-editors, IDEs and web browsers all conspire to make it hard to develop and test algorithms for handling of international text. But a brave Gnome offers the best of two worlds: a level-headed implicit mode for day-to-day usage, and an explicit mode for bidi-nerds. Thank you!\n  </p>\n\n  <p>\n    I will try to wrap my learnings into a <a href=\"https://github.com/npillmayer/cords/tree/main/styled/formatter\" target=\"_blank\" rel=\"nofollow noopener\">Go package</a>, but at the same time I am aware that this is a tiny niche in a programming universe dominated by web applications, where the browser is expected to do all the heavy lifting. But that‚Äôs a different story.\n  </p>",
            "image": "https://npillmayer.github.io/media/posts/6/Unicode-Bidi2.png",
            "author": {
                "name": "Norbert Pillmayer"
            },
            "tags": [
                   "Unicode",
                   "Typography"
            ],
            "date_published": "2021-02-24T15:31:00+01:00",
            "date_modified": "2026-01-18T16:26:11+01:00"
        },
        {
            "id": "https://npillmayer.github.io/posts/the-perils-of-segmenting-text/",
            "url": "https://npillmayer.github.io/posts/the-perils-of-segmenting-text/",
            "title": "‚ãÆThe‚ãÆ ‚ãÆPer‚ãÆils‚ãÆ ‚ãÆof‚ãÆ ‚ãÆSeg‚ãÆment‚ãÆing‚ãÆ ‚ãÆText‚ãÆ¬†",
            "summary": "Text processing applications need to segment text into pieces. Segments may be word, sentences, paragraphs and so on. For western languages this is not too hard of a problem,&hellip;",
            "content_html": "\n  <p>\n    Text processing applications need to segment text into pieces. Segments may be word, sentences, paragraphs and so on. For western languages this is not too hard of a problem, but it may become an involved endeavor if you consider Arabic or Asian languages. From a typographic viewpoint some of these languages present serious challenges for correct segmenting. The Unicode consortium publishes recommendations and algorithms for various aspects of text segmentation in their Unicode Annexes (UAX).\n  </p>\n\n    <h2 id=\"text-segmentation-in-golang\">\n      Text Segmentation in Go(lang)\n    </h2>\n\n  <p>\n    There exist a number of Unicode standards describing best practices for text segmentation. Unfortunately, implementations in Go are sparse. Marcel van Lohuizen from the Go Core Team seems to be working on text segmenting, but with low priority. In the long run, it will be best to wait for the standard library to include functions for text segmentation. However, for now I will implement my own.\n  </p>\n\n    <h2 id=\"tradeoffs\">\n      Tradeoffs\n    </h2>\n\n  <p>\n    Handling character data is often part of the inner loop of applications, requiring fast implementations. The flip side are tiring implementations, with lots and lots of boring code. This is something I learned from working on text processing: I am even more susceptible to boredom than I suspected. In the Unicode committee world there are lots of brave people involved who spend a lot of energy on getting the details right. Progress in international language processing wouldn‚Äôt be possible without them‚Äìmy thanks to every single one of them.\n  </p>\n\n  <p>\n    I need a different approach, however. If your concern is all about efficiency and performance, you will probably shy away from U‚ãÆA‚ãÆX. I try to find a balance between performance and readability. Unicode algorithms are often stated as formal rules. Implementations in the wild usually follow these descriptions in a procedural manner, resulting in hard-to-read code for travelling back and forth in byte buffers. I won‚Äôt do that. Instead I prefer to design a programming environment which allows me to <em>put in the problem description</em> (i.e., the UAX-rules) and get a working algorithm out. Oftentimes that‚Äôs tougher and more time-consuming than a straightforward implementation‚Äìbut hey!, Open Source development is about fun.\n  </p>",
            "image": "https://npillmayer.github.io/media/posts/5/UAX-Logo-framed-2.png",
            "author": {
                "name": "Norbert Pillmayer"
            },
            "tags": [
                   "Unicode",
                   "Typography"
            ],
            "date_published": "2021-01-18T14:10:00+01:00",
            "date_modified": "2026-01-18T16:26:48+01:00"
        },
        {
            "id": "https://npillmayer.github.io/posts/why-gorgo/",
            "url": "https://npillmayer.github.io/posts/why-gorgo/",
            "title": "Why GoRGO?",
            "summary": "Every software developer hates repetitive tasks. What‚Äôs the point of being a programmer if you can‚Äôt delegate your chores to a machine? And as a backend developer you are&hellip;",
            "content_html": "\n  <p>\n    Every software developer hates repetitive tasks. What‚Äôs the point of being a programmer if you can‚Äôt delegate your chores to a machine? And as a backend developer you are most likely open to the idea to employ some kind of domain specific language (DSL). That‚Äôs where a compiler generator may come into play. There is no shortage of them, ranging from good old <em>bison</em> to <em>ANTLR</em> and various Go variants like <em>gocc</em>. Why develop another one? Because GoRGO is a little different.\n  </p>\n\n    <h3 id=\"what-is-it-about\">\n      What is it about?\n    </h3>\n\n  <p>\n    I have used many of the aforementioned tools extensively in my life, plus a handful of situations where I‚Äôve written recursive descent parsers by hand. All these tools have their value and I appreciate the availability of compiler-compilers with a lot of horse power. But on the other hand, sometimes I want something more compact, a smart and lightweight tool to generate an interpreter for a custom language. And I want it in native Go, as this is what I currently use for Open Source. That‚Äôs what GoRGO strives to be.\n  </p>\n\n    <h3 id=\"the-name\">\n      The Name\n    </h3>\n\n  <p>\n    The ‚ÄúRGO‚Äù in GoRGO stands for <strong>R</strong>ight-derivated <strong>G</strong>rammar <strong>O</strong>perations, which may sound all gibberish to you (and I wouldn‚Äôt blame you). But there‚Äôs a hint in this name: we will focus on LR-parsing, i.e., we will construct bottom-up parsers which produce right-derivations. That‚Äôs exactly what <em>yacc</em> et al do (unlike <em>ANTLR</em>, which produces LL-parsers), so no surprise there‚Äîor is it? In fact it should be, as DSL parsers these days are implemented with PEGs most of the time. But PEGs (parser expression grammars) are top-down, so why opt for bottom-up parsing?\n  </p>\n<div><div class=\"sidebox\"><h5>Gorgosaurus</h5><p>Gorgo‚ãÖsaurus (<em>fierce lizard‚Äâ</em>) was not quite as big or famous as Tyrannosaurus Rex, but dangerous nevertheless. It lived some 75 million years ago in Northern America, <strong>eating anything</strong> it came across. We will meet its cousin T-Rex again when we'll talk about TeREx, a term rewriter.&nbsp;</p></aside></div>\n\n  <p>\n    PEG parsers have a number of disadvantages for the careless user‚Äîwhich includes myself. Although I love their simplicity, they lack a certain foolproofness which I expect for ad-hoc DSLs. Most ad-hoc grammars people write contain <em>ambiguous rules</em>, and PEGs hide ambiguity rather than resolving it. On the other hand, we do not want programmers to have to fix shift|reduce-conflicts and the like. The tool should just eat my grammar! Therefore we revert to LR-parsers, acknowledging the fact that we have to convince the parser to not be so tough on its users.\n  </p>\n\n    <h3 id=\"no-code-generation\">\n      No Code Generation\n    </h3>\n\n  <p>\n    Parser generators (compiler compilers) usually generate source code. That‚Äôs often a good idea, as many of these tools can handle a multitude of host-languages. Moreover, Go has a mechanism for preprocessing and code-generation (<code>go-generate</code>) which is well suited for parser generators. However, for small DSLs I prefer to skip a code-generation step and rather create the parser in place and immediately run it.\n  </p>\n\n  <p>\n    Digesting the grammar is always the first step. This results in a bunch of <em>LR parse tables</em>. Instead of saving these tables as source code into a file, we keep them in memory and provide them to a parser. Table generation is quick for small languages and we usually can afford to go through this step once per program execution.\n  </p>\n\n    <h3 id=\"ambiguous-grammars\">\n      Ambiguous Grammars\n    </h3>\n\n  <p>\n    Conventional parser generator do not handle ambiguous grammars well. Especially for ad-hoc DSLs, however, grammar ambiguity is quite common. Parser which can handle these kinds of grammars have been known for some time, but rarely gained popularity (<em>bison‚Äôs</em> GLR-feature is an exception to this rule and <em>ANTLR</em> mitigates many of these problems, too). GoRGO implementes two flavors of bottom-up parsers which are able to cope with ambiguty: Earley parsing and GLR-parsing.\n  </p>\n\n  <p>\n    During tests for various DSL tasks I came to love Earley-parsing. Sketching out a grammar, attaching it into an Earley parser and feeding it some sample input, all with a couple lines of code, is a satisfying experience. In theory Earley parsing can severly degrade in performance, but I have yet to come across such a case in practice. I will talk more on Earley-parsing in a different post.\n  </p>\n\n  <p>\n    GoRGO is an ongoing experiment. Stay tuned for some real-world application stories.\n  </p>",
            "image": "https://npillmayer.github.io/media/posts/1/GoRGO-Logo-small.png",
            "author": {
                "name": "Norbert Pillmayer"
            },
            "tags": [
                   "Parsing"
            ],
            "date_published": "2021-01-02T20:28:00+01:00",
            "date_modified": "2026-01-18T16:28:17+01:00"
        },
        {
            "id": "https://npillmayer.github.io/posts/parsing-metapost/",
            "url": "https://npillmayer.github.io/posts/parsing-metapost/",
            "title": "Parsing MetaPost",
            "summary": "These days I spend some evenings programming a variant of MetaPost, a DSL for diagrams and illustrations. MetaPost inherits much of its syntax from MetaFont, which has been designed&hellip;",
            "content_html": "<p>These days I spend some evenings programming a variant of <a target=\"_blank\" rel=\"nofollow noopener noreferrer\">MetaPost</a>, a DSL for diagrams and illustrations. MetaPost inherits much of its syntax from <a href=\"https://www.texfaq.org/FAQ-MF\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">MetaFont</a>, which has been designed by D.‚ÄâE.‚ÄâKnuth. Mr¬†Knuth is the ‚Äúfather of LR-parsing,‚Äù so one would expect some interesting language features in MetaPost‚Äîand we are not disappointed!</p>\n<h2>What MetaPost does</h2>\n<p>MetaPost‚Äôs unique selling point is its ability to solve linear equations. In some situations, you‚Äôd rather not specifiy a point position, but let the computer figure out its location. Let‚Äôs take a look at an example:</p>\n<figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://npillmayer.github.io/media/posts/4/MP-Example.png\" alt=\"MetaPost code example\" width=\"1722\" height=\"920\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://npillmayer.github.io/media/posts/4/responsive/MP-Example-xs.png 320w ,https://npillmayer.github.io/media/posts/4/responsive/MP-Example-sm.png 480w ,https://npillmayer.github.io/media/posts/4/responsive/MP-Example-md.png 768w ,https://npillmayer.github.io/media/posts/4/responsive/MP-Example-xl.png 1024w\"></figure>\n<p>Don‚Äôt worry if this looks a bit like your last mathematics exam. The unique part are the lines like <code>A'=whatever[A,C];</code>. This is MetaPost‚Äôs way of requesting a point <em>A</em>' to lie <em>somewhere</em> on the line between points <em>A</em> and <em>C</em>. Given that <em>A</em>' should lie on [<em>A</em>,<em>C</em>‚Äâ] as well as on [<em>B</em>,<em>D</em>‚Äâ], MetaPost will find the intersection point by solving a set of linear equations. That‚Äôs a pretty cool feature! However, we will talk about MetaPost's features in another post.</p>\n<h2 id=\"variables-its-complicated\">Variables: It‚Äôs complicated‚Ä¶</h2>\n<p>The MetaPost language is designed to be somewhat reminiscent of mathematical writing. This is especially noticeable with its conventions for variable names. You already caught a glimpse of that with those primed point variables (<em>A</em>'), but that‚Äôs not the end of it. MetaPost will happily digest identifiers like <span class=\"katex\"><span class=\"katex-mathml\">zr‚Ä≤</span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"mord\"><span class=\"mord mathnormal\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\"><span class=\"\"><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">r</span></span></span><span class=\"\"><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">‚Ä≤</span></span></span></span><span class=\"vlist-s\">‚Äã</span></span></span></span></span></span></span></span> (denoted as <code>z'.r</code>) and <span class=\"katex\"><span class=\"katex-mathml\">x1</span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\"><span class=\"\"><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">‚Äã</span></span></span></span></span></span></span></span> (<code>x1</code>). Add to this the ability to handle fractions as numeric input, you are free to instruct MetaPost to calculate</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\">‚àí13x1</span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"mord\">‚àí</span><span class=\"mord\"><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\"><span class=\"\">3</span><span class=\"\">1</span></span><span class=\"vlist-s\">‚Äã</span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\"><span class=\"\"><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">‚Äã</span></span></span></span></span></span></span></span></span></p>\n<p>by typing <code>-1/3x1</code>. That might not appeal to everyone, but it sure is easy to type and MetaPost will usually understand what you had in mind.</p>\n<p>Those variable names look innocent enough, but from a parser‚Äôs point they carry slightly different semantics than with other programming languages. Let‚Äôs consider the input <code>7 - -a1r</code>. By now you propably could guess that this means ‚Äú<span class=\"katex\"><span class=\"katex-mathml\">7‚àí‚àía1r</span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"mord\">7</span><span class=\"mbin\">‚àí</span></span><span class=\"base\"><span class=\"mord\">‚àí</span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\"><span class=\"\"><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1<span class=\"mord mathnormal mtight\">r</span></span></span></span></span><span class=\"vlist-s\">‚Äã</span></span></span></span></span></span></span></span>.‚Äù Setting aside that you should enclose the second term in parenthesis anyway, put yourself in the shoes of the parser: it will see a sequence of tokens like <code>7 - - a 1 r</code>. And just when you successfully taught your parser to accept it, someone types in <code>y = 7 - - 1 / 3 x [ n - 1 ]</code>, intending to express the equation</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\">y=7‚àí‚àí13xn‚àí1</span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"mord mathnormal\">y</span><span class=\"mrel\">=</span></span><span class=\"base\"><span class=\"mord\">7</span><span class=\"mbin\">‚àí</span></span><span class=\"base\"><span class=\"mord\">‚àí</span><span class=\"mord\"><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\"><span class=\"\">3</span><span class=\"\">1</span></span><span class=\"vlist-s\">‚Äã</span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\"><span class=\"\"><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mbin mtight\">‚àí</span>1</span></span></span></span><span class=\"vlist-s\">‚Äã</span></span></span></span></span></span></span></span></span></p>\n<p>Let‚Äôs try with Python:</p>\n<pre><code>&gt;&gt;&gt; n = 2    # pre-set subscript variable n\n<br>¬†&gt;&gt;&gt; y = 7 - - 1 / 3 x [ n - 1 ]\n  File \"&lt;stdin&gt;\", line 1\n\ty = 7 - - 1 / 3 x [ n - 1 ]\n\t\t\t\t\t^\nSyntaxError: invalid syntax\n</code></pre>\n<p>We expected that, didn‚Äôt we? The error doesn‚Äôt result from the fact that <em>x</em> is an unknown quantity; it‚Äôs just that Python cannot handle the syntax: it misses a ‚Äò<span style=\"color: #e67e23;\"><strong>*</strong></span>‚Äô before the <em>x</em>. Now let‚Äôs have MetaPost a go:</p>\n<pre><code>This is MetaPost, version 1.999\n**\\relax\n*n:=2;  % pre-set subscript variable n\n*y = 7 - - 1 / 3 x [ n - 1 ];\n*show y;\n&gt;&gt; 0.33333x1+7\n</code></pre>\n<p>The last line is MetaPost‚Äôs way of telling us that variable <em>y</em> is dependent on <span class=\"katex\"><span class=\"katex-mathml\">x1</span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\"><span class=\"\"><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">‚Äã</span></span></span></span></span></span></span></span>, which is of unknown value yet. It is worth noting that <code>[n-1]</code> is not your usual array indexing, but rather the ‚Äúgeneration‚Äù of a mathematical subscript. Just for fun, create an irrational subscript:</p>\n<p>¬†</p>",
            "image": "https://npillmayer.github.io/media/posts/4/pmmp-framed-2.png",
            "author": {
                "name": "Norbert Pillmayer"
            },
            "tags": [
                   "Parsing",
                   "Graphics"
            ],
            "date_published": "2020-12-10T11:40:00+01:00",
            "date_modified": "2026-01-18T15:38:03+01:00"
        }
    ]
}
